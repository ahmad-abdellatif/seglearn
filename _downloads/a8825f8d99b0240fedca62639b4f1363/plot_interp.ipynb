{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Resampling Time Series Data\n\n\nThis is a basic example using the pipeline to learn resample a time series\n\nThis may be useful for resampling irregularly sampled time series, or for determining\nan optimal sampling frequency for the data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: David Burns\n# License: BSD\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\nfrom seglearn.datasets import load_watch\nfrom seglearn.pipe import Pype\nfrom seglearn.split import TemporalKFold\nfrom seglearn.transform import FeatureRep, Segment, Interp\n\n\ndef calc_segment_width(params):\n    # number of samples in a 2 second period\n    period = params['interp__sample_period']\n    return int(2. / period)\n\n\n# seed RNGESUS\nnp.random.seed(123124)\n\n# load the data\ndata = load_watch()\n\nX = data['X']\ny = data['y']\n\n# I am adding in a column to represent time (50 Hz sampling), since my data doesn't include it\n# the Interp class assumes time is the first column in the series\nX = np.array([np.column_stack([np.arange(len(X[i])) / 50., X[i]]) for i in np.arange(len(X))])\n\nclf = Pype([('interp', Interp(1. / 25., categorical_target=True)),\n            ('segment', Segment(width=100)),\n            ('features', FeatureRep()),\n            ('scaler', StandardScaler()),\n            ('rf', RandomForestClassifier(n_estimators=20))])\n\n# split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n\nclf.fit(X_train, y_train)\nscore = clf.score(X_test, y_test)\n\nprint(\"N series in train: \", len(X_train))\nprint(\"N series in test: \", len(X_test))\nprint(\"N segments in train: \", clf.N_train)\nprint(\"N segments in test: \", clf.N_test)\nprint(\"Accuracy score: \", score)\n\n# lets try a few different sampling periods\n# temporal splitting of data\nsplitter = TemporalKFold(n_splits=3)\nXs, ys, cv = splitter.split(X, y)\n\n# here we use a callable parameter to force the segmenter width to equal 2 seconds\n# note this is an extension of the sklearn api for setting class parameters\npar_grid = {'interp__sample_period': [1. / 5., 1. / 10., 1. / 25., 1. / 50.],\n            'segment__width': [calc_segment_width]}\n\nclf = GridSearchCV(clf, par_grid, cv=cv)\nclf.fit(Xs, ys)\nscores = clf.cv_results_['mean_test_score']\nstds = clf.cv_results_['std_test_score']\n\nplt.plot(par_grid['interp__sample_period'], scores, '-o')\nplt.title(\"Grid Search Scores\")\nplt.xlabel(\"Sample Period [s]\")\nplt.ylabel(\"CV Average Score\")\nplt.fill_between(par_grid['interp__sample_period'], scores - stds, scores + stds, alpha=0.2,\n                 color='navy')\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}