{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Basic Feature Representation Classification Pipeline\n\n\nThis is a basic example using the pipeline to learn a feature representation of the time series data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: David Burns\n# License: BSD\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, make_scorer\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.preprocessing import StandardScaler\n\nfrom seglearn.base import TS_Data\nfrom seglearn.datasets import load_watch\nfrom seglearn.pipe import Pype\nfrom seglearn.transform import FeatureRep, Segment\n\n# seed RNGESUS\nnp.random.seed(123124)\n\n# load the data\ndata = load_watch()\nX = data['X']\ny = data['y']\n\n# create a feature representation pipeline\nclf = Pype([('segment', Segment()),\n            ('features', FeatureRep()),\n            ('scaler', StandardScaler()),\n            ('rf', RandomForestClassifier(n_estimators=20))])\n\n# split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n\nclf.fit(X_train, y_train)\nscore = clf.score(X_test, y_test)\n\nprint(\"N series in train: \", len(X_train))\nprint(\"N series in test: \", len(X_test))\nprint(\"N segments in train: \", clf.N_train)\nprint(\"N segments in test: \", clf.N_test)\nprint(\"Accuracy score: \", score)\n\n# lets make a pretend series with different activities\nX_series = np.concatenate(X_test[1:4], axis=0)\ny_series = np.concatenate([np.full(len(X_test[i]), y_test[i]) for i in range(1, 4)])\nprint(\"Pretend series y values: \", y_test[1:4])\n\n# plot the prediction\nyp = clf.predict_unsegmented([X_series], categorical_target=True)\nyp0 = yp[0]  # we only predicted one series\nt = np.arange(len(yp0)) * 0.02   # This data has 50 Hz sampling rate\nplt.plot(t, yp0, label='predicted')\nplt.plot(t, y_series, label='actual')\nplt.ylabel(\"Prediction\")\nplt.xlabel(\"Time [seconds]\")\nplt.legend()\nplt.show()\n\n# let's try some context data\nXc = np.column_stack((data['side'], data['subject']))\nXt = np.array(data['X'])\nX = TS_Data(Xt, Xc)\ny = np.array(data['y'])\n\n# and a cross validation\nscoring = make_scorer(f1_score, average='macro')\ncv_scores = cross_validate(clf, X, y, cv=4, return_train_score=True)\nprint(\"CV Scores: \", pd.DataFrame(cv_scores))\n\n# lets see what feature we used\nprint(\"Features: \", clf.steps[1][1].f_labels)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}